{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>A simple Chatbot using NLTK<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NLTK(Natural Language Toolkit)** is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('popular', quiet=True) \n",
    "#nltk.download('punkt') # first-time use only\n",
    "#nltk.download('wordnet') # first-time use only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading in the corpus**\n",
    "\n",
    "we will be using the Wikipedia page for chatbots as our corpus. Copy the contents from the page and place it in a text file named ‘chatbot.txt’. However, you can use any corpus of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Analytics.txt\",'r') as f:\n",
    "    data = f.read()\n",
    "    data = data.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f=open('Analytics.txt','r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw = raw.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿\n",
      "analytics\n",
      "from wikipedia, the free encyclopedia\n",
      "jump to navigationjump to search\n",
      "for the ice hockey term, see analytics (ice hockey).\n",
      "analytics is the systematic computational analysis of data or statistics.[1] it is used for the discovery, interpretation, and communication of meaningful patterns in data. it also entails applying data patterns towards effective decision making. it can be valuable in areas rich with recorded information; analytics relies on the simultaneous application of statistics, computer programming and operations research to quantify performance.\n",
      "\n",
      "organizations may apply analytics to business data to describe, predict, and improve business performance. specifically, areas within analytics include predictive analytics, prescriptive analytics, enterprise decision management, descriptive analytics, cognitive analytics, big data analytics, retail analytics, supply chain analytics, store assortment and stock-keeping unit optimization, marketing optimization and marketing mix modeling, web analytics, call analytics, speech analytics, sales force sizing and optimization, price and promotion modeling, predictive science, graph analytics, credit risk analysis, and fraud analytics. since analytics can require extensive computation (see big data), the algorithms and software used for analytics harness the most current methods in computer science, statistics, and mathematics.[2]\n",
      "\n",
      "\n",
      "traffic analysis of english wikipedia itself\n",
      "\n",
      "contents\n",
      "1\tanalytics vs. analysis\n",
      "2\tapplications\n",
      "2.1\tmarketing optimization\n",
      "2.2\tpeople analytics\n",
      "2.3\tportfolio analytics\n",
      "2.4\trisk analytics\n",
      "2.5\tdigital analytics\n",
      "2.6\tsecurity analytics\n",
      "2.7\tsoftware analytics\n",
      "3\tchallenges\n",
      "4\trisks\n",
      "5\tsee also\n",
      "6\treferences\n",
      "7\texternal links\n",
      "analytics vs. analysis\n",
      "\n",
      "this section may be confusing or unclear to readers. in particular, it is still not clear what the difference between analytics and analysis is. please help us clarify the section. there might be a discussion about this on the talk page. (march 2018) (learn how and when to remove this template message)\n",
      "analysis is focused on understanding the past; what happened and why it happened. analytics focuses on why it happened and what will happen in the future.[3]\n",
      "\n",
      "data analytics is a multidisciplinary field. there is extensive use of computer skills, mathematics, statistics, the use of descriptive techniques and predictive models to gain valuable knowledge from data through analytics.[citation needed]. the insights from data are used to recommend action or to guide decision making rooted in the business context. thus, analytics is not so much concerned with individual analyses or analysis steps, but with the entire methodology[according to whom?]. there is a pronounced tendency to use the term analytics in business settings e.g. text analytics vs. the more generic text mining to emphasize this broader perspective.[citation needed] there is an increasing use of the term advanced analytics, typically used to describe the technical aspects of analytics, especially in the emerging fields such as the use of machine learning techniques like neural networks, decision tree, logistic regression, linear to multiple regression analysis, classification to do predictive modeling.[4] it also includes unsupervised machine learning techniques like cluster analysis, principal component analysis, segmentation profile analysis and association analysis.[5]\n",
      "\n",
      "applications\n",
      "marketing optimization\n",
      "marketing has evolved from a creative process into a highly data-driven process. marketing organizations use analytics to determine the outcomes of campaigns or efforts and to guide decisions for investment and consumer targeting. demographic studies, customer segmentation, conjoint analysis and other techniques allow marketers to use large amounts of consumer purchase, survey and panel data to understand and communicate marketing strategy.\n",
      "\n",
      "marketing analytics consists of both qualitative and quantitative, structured and unstructured data used to drive strategic decisions in relation to brand and revenue outcomes. the process involves predictive modelling, marketing experimentation, automation and real-time sales communications. the data enables companies to make predictions and alter strategic execution to maximize performance results.\n",
      "\n",
      "web analytics allows marketers to collect session-level information about interactions on a website using an operation called sessionization. google analytics is an example of a popular free analytics tool that marketers use for this purpose. those interactions provide web analytics information systems with the information necessary to track the referrer, search keywords, identify ip address, and track activities of the visitor. with this information, a marketer can improve marketing campaigns, website creative content, and information architecture.\n",
      "\n",
      "analysis techniques frequently used in marketing include marketing mix modeling, pricing and promotion analyses, sales force optimization and customer analytics e.g.: segmentation. web analytics and optimization of web sites and online campaigns now frequently work hand in hand with the more traditional marketing analysis techniques. a focus on digital media has slightly changed the vocabulary so that marketing mix modeling is commonly referred to as attribution modeling in the digital or marketing mix modeling context.\n",
      "\n",
      "these tools and techniques support both strategic marketing decisions (such as how much overall to spend on marketing, how to allocate budgets across a portfolio of brands and the marketing mix) and more tactical campaign support, in terms of targeting the best potential customer with the optimal message in the most cost effective medium at the ideal time.\n",
      "\n",
      "people analytics\n",
      "people analytics is using behavioral data to understand how people work and change how companies are managed.[6]\n",
      "\n",
      "people analytics is also known as workforce analytics, hr analytics, talent analytics, people insights, talent insights, colleague insights, human capital analytics, and hris analytics. hr analytics is the application of analytics to help companies manage human resources.[7] additionally, hr analytics has become a strategic tool in analyzing and forecasting human related trends in the changing labor markets, using career analytics tools.[8] the aim is to discern which employees to hire, which to reward or promote, what responsibilities to assign, and similar human resource problems.[9] hr analytics is becoming increasingly important to understand what kind of behavioral profiles would succeed and fail. for example, an analysis may find that individuals that fit a certain type of profile are those most likely to succeed at a particular role, making them the best employees to hire.\n",
      "\n",
      "it has been suggested that people analytics is a separate discipline to hr analytics, representing a greater focus on business issues rather than administrative processes,[10] and that people analytics may not really belong within human resources in organizations.[11] however, experts disagree on this, with many arguing that human resources will need to develop people analytics as a key part of a more capable and strategic business function in the changing world of work brought on by automation.[12] instead of moving people analytics outside hr, some experts argue that it belongs in hr, albeit enabled by a new breed of hr professional who is more data-driven and business savvy.[13]\n",
      "\n",
      "portfolio analytics\n",
      "a common application of business analytics is portfolio analysis. in this, a bank or lending agency has a collection of accounts of varying value and risk. the accounts may differ by the social status (wealthy, middle-class, poor, etc.) of the holder, the geographical location, its net value, and many other factors. the lender must balance the return on the loan with the risk of default for each loan. the question is then how to evaluate the portfolio as a whole.\n",
      "\n",
      "the least risk loan may be to the very wealthy, but there are a very limited number of wealthy people. on the other hand, there are many poor that can be lent to, but at greater risk. some balance must be struck that maximizes return and minimizes risk. the analytics solution may combine time series analysis with many other issues in order to make decisions on when to lend money to these different borrower segments, or decisions on the interest rate charged to members of a portfolio segment to cover any losses among members in that segment.\n",
      "\n",
      "risk analytics\n",
      "predictive models in the banking industry are developed to bring certainty across the risk scores for individual customers. credit scores are built to predict individual's delinquency behavior and widely used to evaluate the credit worthiness of each applicant. furthermore, risk analyses are carried out in the scientific world and the insurance industry. it is also extensively used in financial institutions like online payment gateway companies to analyse if a transaction was genuine or fraud. for this purpose they use the transaction history of the customer. this is more commonly used in credit card purchase, when there is a sudden spike in the customer transaction volume the customer gets a call of confirmation if the transaction was initiated by him/her. this helps in reducing loss due to such circumstances.\n",
      "\n",
      "digital analytics\n",
      "digital analytics is a set of business and technical activities that define, create, collect, verify or transform digital data into reporting, research, analyses, recommendations, optimizations, predictions, and automations.[14] this also includes the seo (search engine optimization) where the keyword search is tracked and that data is used for marketing purposes. even banner ads and clicks come under digital analytics. a growing number of brands and marketing firms rely on digital analytics for their digital marketing assignments, where mroi (marketing return on investment) is an important key performance indicator (kpi).\n",
      "\n",
      "security analytics\n",
      "security analytics refers to information technology (it) to gather security events to understand and analyze events that pose the greatest risk.[15] products in this area include security information and event management and user behavior analytics.\n",
      "\n",
      "software analytics\n",
      "main article: software analytics\n",
      "software analytics is the process of collecting information about the way a piece of software is used and produced.\n",
      "\n",
      "challenges\n",
      "in the industry of commercial analytics software, an emphasis has emerged on solving the challenges of analyzing massive, complex data sets, often when such data is in a constant state of change. such data sets are commonly referred to as big data. whereas once the problems posed by big data were only found in the scientific community, today big data is a problem for many businesses that operate transactional systems online and, as a result, amass large volumes of data quickly.[16]\n",
      "\n",
      "the analysis of unstructured data types is another challenge getting attention in the industry. unstructured data differs from structured data in that its format varies widely and cannot be stored in traditional relational databases without significant effort at data transformation.[17] sources of unstructured data, such as email, the contents of word processor documents, pdfs, geospatial data, etc., are rapidly becoming a relevant source of business intelligence for businesses, governments and universities.[18] for example, in britain the discovery that one company was illegally selling fraudulent doctor's notes in order to assist people in defrauding employers and insurance companies,[19] is an opportunity for insurance firms to increase the vigilance of their unstructured data analysis. the mckinsey global institute estimates that big data analysis could save the american health care system $300 billion per year and the european public sector â‚¬250 billion.[20]\n",
      "\n",
      "these challenges are the current inspiration for much of the innovation in modern analytics information systems, giving birth to relatively new machine analysis concepts such as complex event processing, full text search and analysis, and even new ideas in presentation.[21] one such innovation is the introduction of grid-like architecture in machine analysis, allowing increases in the speed of massively parallel processing by distributing the workload to many computers all with equal access to the complete data set.[22]\n",
      "\n",
      "analytics is increasingly used in education, particularly at the district and government office levels. however, the complexity of student performance measures presents challenges when educators try to understand and use analytics to discern patterns in student performance, predict graduation likelihood, improve chances of student success, etc. for example, in a study involving districts known for strong data use, 48% of teachers had difficulty posing questions prompted by data, 36% did not comprehend given data, and 52% incorrectly interpreted data.[23] to combat this, some analytics tools for educators adhere to an over-the-counter data format (embedding labels, supplemental documentation, and a help system, and making key package/display and content decisions) to improve educators' understanding and use of the analytics being displayed.[24]\n",
      "\n",
      "one more emerging challenge is dynamic regulatory needs. for example, in the banking industry, basel iii and future capital adequacy needs are likely to make even smaller banks adopt internal risk models. in such cases, cloud computing and open source programming language r can help smaller banks to adopt risk analytics and support branch level monitoring by applying predictive analytics.[citation needed]\n",
      "\n",
      "risks\n",
      "\n",
      "this article possibly contains original research. please improve it by verifying the claims made and adding inline citations. statements consisting only of original research should be removed. (march 2015) (learn how and when to remove this template message)\n",
      "the main risk for the people is discrimination like price discrimination or statistical discrimination. see scientific american book review of \"weapons of math destruction\"\n",
      "\n",
      "there is also the risk that a developer could profit from the ideas or work done by users, like this example: users could write new ideas in a note taking app, which could then be sent as a custom event, and the developers could profit from those ideas. this can happen because the ownership of content is usually unclear in the law.[25]\n",
      "\n",
      "if a user's identity is not protected, there are more risks; for example, the risk that private information about users is made public on the internet.\n",
      "\n",
      "in the extreme, there is the risk that governments could gather too much private information, now that the governments are giving themselves more powers to access citizens' information.\n",
      "\n",
      "further information: telecommunications data retention\n",
      "see also\n",
      "analysis\n",
      "analytic applications\n",
      "architectural analytics\n",
      "behavioral analytics\n",
      "business analytics\n",
      "business intelligence\n",
      "cloud analytics\n",
      "complex event processing\n",
      "continuous analytics\n",
      "cultural analytics\n",
      "customer analytics\n",
      "dashboard\n",
      "data mining\n",
      "data presentation architecture\n",
      "embedded analytics\n",
      "learning analytics\n",
      "list of software engineering topics\n",
      "mobile location analytics\n",
      "news analytics\n",
      "online analytical processing\n",
      "online video analytics\n",
      "operational reporting\n",
      "operations research\n",
      "prediction\n",
      "predictive analytics\n",
      "predictive engineering analytics\n",
      "prescriptive analytics\n",
      "semantic analytics\n",
      "smart grid\n",
      "social analytics\n",
      "software analytics\n",
      "speech analytics\n",
      "statistics\n",
      "user behavior analytics\n",
      "visual analytics\n",
      "web analytics\n",
      "winâ€“loss analytics\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main issue with text data is that it is all in text format (strings). However, the Machine learning algorithms need some sort of numerical feature vector in order to perform the task. So before we start with any NLP project we need to pre-process it to make it ideal for working. Basic text pre-processing includes:\n",
    "\n",
    "Converting the entire text into uppercase or lowercase, so that the algorithm does not treat the same words in different cases as different\n",
    "\n",
    "**Tokenization**: Tokenization is just the term used to describe the process of converting the normal text strings into a list of tokens i.e words that we actually want. Sentence tokenizer can be used to find the list of sentences and Word tokenizer can be used to find the list of words in strings.\n",
    "\n",
    "The NLTK data package includes a pre-trained Punkt tokenizer for English.\n",
    "\n",
    "**Removing Noise** i.e everything that isn’t in a standard number or letter.\n",
    "Removing the Stop words. Sometimes, some extremely common words which would appear to be of little value in helping select documents matching a user need are excluded from the vocabulary entirely. These words are called stop words\n",
    "Stemming: Stemming is the process of reducing inflected (or sometimes derived) words to their stem, base or root form — generally a written word form. Example if we were to stem the following words: “Stems”, “Stemming”, “Stemmed”, “and Stemtization”, the result would be a single word “stem”.\n",
    "Lemmatization: A slight variant of stemming is lemmatization. The major difference between these is, that, stemming can often create non-existent words, whereas lemmas are actual words. So, your root stem, meaning the word you end up with, is not something you can just look up in a dictionary, but you can look up a lemma. Examples of Lemmatization are that “run” is a base form for words like “running” or “ran” or that the word “better” and “good” are in the same lemma so they are considered the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = nltk.sent_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens = nltk.word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Corpus using Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lem_function(tokens):\n",
    "    return (lemmatizer.lemmatize(token) for token in tokens)\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def lem_normalize(text):\n",
    "    return lem_function(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Matching\n",
    "\n",
    "Next, we shall define a function for a greeting by the bot i.e if a user’s input is a greeting, the bot shall return a greeting response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "\n",
    "GREETING_RESPONSES = [\"hi :)\", \"hey :)\", \"*nods*\", \"hi there :)\", \"hello :)\", \"Hello,How can I help you? :)\"]\n",
    "\n",
    "def greeting(sentence):\n",
    " \n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    titu_response= ''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=lem_normalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2] # argsort sorts the index\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        titu_response=titu_response+\"I am sorry! I don't understand you\"\n",
    "        return titu_response\n",
    "    else:\n",
    "        titu_response = titu_response+sent_tokens[idx]\n",
    "        return titu_response "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed the lines to Titu what he will respond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITU: My name is Titu. I will answer your queries about Chatbots. If you want to exit, type Bye!\n",
      "hello\n",
      "TITU: hi :)\n",
      "whatsup\n",
      "TITU: I am sorry! I don't understand you\n",
      "Analytics\n",
      "TITU: further information: telecommunications data retention\n",
      "see also\n",
      "analysis\n",
      "analytic applications\n",
      "architectural analytics\n",
      "behavioral analytics\n",
      "business analytics\n",
      "business intelligence\n",
      "cloud analytics\n",
      "complex event processing\n",
      "continuous analytics\n",
      "cultural analytics\n",
      "customer analytics\n",
      "dashboard\n",
      "data mining\n",
      "data presentation architecture\n",
      "embedded analytics\n",
      "learning analytics\n",
      "list of software engineering topics\n",
      "mobile location analytics\n",
      "news analytics\n",
      "online analytical processing\n",
      "online video analytics\n",
      "operational reporting\n",
      "operations research\n",
      "prediction\n",
      "predictive analytics\n",
      "predictive engineering analytics\n",
      "prescriptive analytics\n",
      "semantic analytics\n",
      "smart grid\n",
      "social analytics\n",
      "software analytics\n",
      "speech analytics\n",
      "statistics\n",
      "user behavior analytics\n",
      "visual analytics\n",
      "web analytics\n",
      "winâ€“loss analytics\n",
      "great\n",
      "TITU: I am sorry! I don't understand you\n",
      "bye\n",
      "TITU: Bye! take care..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flag=True\n",
    "print(\"TITU: My name is Titu. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"TITU: You are welcome..\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"TITU: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"TITU: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"TITU: Bye! take care..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
